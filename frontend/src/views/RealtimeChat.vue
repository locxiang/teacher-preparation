<template>
  <div class="h-full w-full bg-gradient-to-br from-nanyu-50 to-gray-100 flex flex-col overflow-hidden">
    <!-- é¡¶éƒ¨å›ºå®šæ  -->
    <div class="bg-white/80 backdrop-blur-sm border-b border-gray-200 flex-shrink-0 z-10 shadow-sm">
      <div class="max-w-[1600px] mx-auto px-8 py-4">
        <div class="flex items-center justify-between">
          <div>
            <h1 class="text-2xl font-semibold text-gray-900">AI å®æ—¶è¯­éŸ³é€šè¯</h1>
            <p class="text-sm text-gray-500 mt-1">ä¸AIè¿›è¡Œå®æ—¶è¯­éŸ³å¯¹è¯ï¼Œæ”¯æŒè¯­éŸ³è¾“å…¥å’Œè¯­éŸ³è¾“å‡º</p>
          </div>
          <div class="flex items-center space-x-4">
            <!-- è¯­éŸ³å¼€å…³ -->
            <label class="flex items-center cursor-pointer">
              <input
                type="checkbox"
                v-model="enableVoiceOutput"
                class="w-4 h-4 text-nanyu-600 border-gray-300 rounded focus:ring-nanyu-500"
              />
              <span class="ml-2 text-sm text-gray-700">è¯­éŸ³æ’­æ”¾</span>
            </label>
            <!-- æ¸…ç©ºå¯¹è¯æŒ‰é’® -->
            <button
              @click="clearChat"
              class="px-4 py-2 text-sm bg-gray-100 text-gray-700 rounded hover:bg-gray-200 transition-colors font-medium"
            >
              æ¸…ç©ºå¯¹è¯
            </button>
          </div>
        </div>
      </div>
    </div>

    <!-- ä¸»å†…å®¹åŒºåŸŸ -->
    <div class="flex-1 overflow-hidden flex max-w-[1600px] mx-auto w-full px-8 py-6 gap-6 min-h-0" style="height: 0;">
      <!-- å·¦ä¾§ï¼šé€šè¯ç•Œé¢ -->
      <div class="w-2/5 flex flex-col items-center justify-center space-y-8 overflow-hidden min-h-0">
        <!-- é€šè¯çŠ¶æ€æ˜¾ç¤º -->
        <div class="text-center w-full">
          <div class="text-4xl font-bold text-gray-800 mb-4">
            <span v-if="isRecording && !isAIThinking && !isAISpeaking" class="text-red-600">
              æ­£åœ¨è¯´è¯...
            </span>
            <span v-else-if="isAIThinking" class="text-nanyu-600 flex items-center justify-center">
              <span class="inline-block animate-pulse mr-2">ğŸ¤–</span>
              AIæ€è€ƒä¸­
            </span>
            <span v-else-if="isAISpeaking" class="text-nanyu-600 flex items-center justify-center">
              <span class="inline-block animate-pulse mr-2">ğŸ”Š</span>
              AIæ­£åœ¨è¯´è¯ï¼Œè¯·ç­‰å¾…...
            </span>
            <span v-else class="text-gray-500">
              ç­‰å¾…ä¸­...
            </span>
          </div>

          <!-- å®æ—¶è¯†åˆ«æ–‡å­—æ˜¾ç¤ºåŒºåŸŸ -->
          <div class="w-full max-w-2xl mx-auto">
            <div
              v-if="tempTranscript || (isRecording && !tempTranscript)"
              class="bg-white/90 backdrop-blur-sm border-2 border-dashed rounded-xl shadow-lg p-6 min-h-[120px] flex items-center justify-center"
              :class="tempTranscript ? 'border-nanyu-400' : 'border-gray-300'"
            >
              <div class="w-full">
                <div v-if="tempTranscript" class="text-2xl text-gray-800 font-medium leading-relaxed break-words">
                  {{ tempTranscript }}
                  <span class="inline-block w-1 h-6 bg-nanyu-600 ml-1 animate-pulse"></span>
                </div>
                <div v-else class="text-lg text-gray-400 italic">
                  æ­£åœ¨è¯†åˆ«ä¸­...
                </div>
              </div>
            </div>
            <div
              v-else-if="messages.length > 0 && messages[messages.length - 1].role === 'user'"
              class="bg-white/90 backdrop-blur-sm border border-gray-200 rounded-xl shadow-lg p-6 min-h-[120px] flex items-center justify-center"
            >
              <div class="text-center">
                <div class="text-sm text-gray-500 mb-2">å·²è¯†åˆ«</div>
                <div class="text-xl text-gray-800 font-medium">{{ messages[messages.length - 1].content }}</div>
              </div>
            </div>
            <div
              v-else
              class="bg-white/90 backdrop-blur-sm border-2 border-dashed border-gray-300 rounded-xl shadow-lg p-6 min-h-[120px] flex items-center justify-center"
            >
              <div class="text-lg text-gray-400 italic">ç­‰å¾…è¯­éŸ³è¾“å…¥...</div>
            </div>
          </div>
        </div>

        <!-- éŸ³é¢‘æ³¢å½¢å¯è§†åŒ– -->
        <div class="w-full max-w-2xl">
          <div class="bg-white/80 backdrop-blur-sm border border-gray-200 rounded-2xl shadow-lg p-6">
            <div class="flex items-end justify-center space-x-1 h-32 bg-gradient-to-b from-gray-50 to-gray-100 rounded-xl p-4">
              <div
                v-for="(bar, index) in audioBars"
                :key="index"
                class="flex-1 rounded-t transition-all duration-75"
                :class="isAISpeaking || isAIThinking ? 'bg-nanyu-500' : isRecording ? 'bg-red-500' : 'bg-gray-300'"
                :style="{ height: `${bar}%`, minHeight: '2px' }"
              />
            </div>
          </div>
        </div>

        <!-- å¤§å·é€šè¯æŒ‰é’® -->
        <div class="flex flex-col items-center space-y-4">
          <button
            @click="toggleRecording"
            :disabled="isAIThinking || isAISpeaking"
            :class="[
              'w-32 h-32 rounded-full shadow-2xl transition-all duration-300 flex items-center justify-center',
              isRecording
                ? 'bg-red-600 hover:bg-red-700 scale-110 animate-pulse'
                : 'bg-nanyu-600 hover:bg-nanyu-700 hover:scale-105',
              (isAIThinking || isAISpeaking) ? 'opacity-50 cursor-not-allowed' : 'cursor-pointer'
            ]"
            :title="isAISpeaking ? 'AIæ­£åœ¨è¯´è¯ï¼Œè¯·ç­‰å¾…è¯´å®Œåå†å¼€å§‹å¯¹è¯' : isAIThinking ? 'AIæ­£åœ¨æ€è€ƒä¸­...' : ''"
          >
            <svg
              v-if="!isRecording"
              class="w-16 h-16 text-white"
              fill="none"
              stroke="currentColor"
              viewBox="0 0 24 24"
            >
              <path
                stroke-linecap="round"
                stroke-linejoin="round"
                stroke-width="2"
                d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
              />
            </svg>
            <svg
              v-else
              class="w-16 h-16 text-white"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path d="M6 6h12v12H6z" />
            </svg>
          </button>
          <p class="text-sm text-gray-600">
            {{ isRecording ? 'ç‚¹å‡»åœæ­¢å½•éŸ³' : 'ç‚¹å‡»å¼€å§‹è¯´è¯' }}
          </p>
        </div>

        <!-- é€šè¯ä¿¡æ¯ -->
        <div class="flex items-center space-x-6 text-sm text-gray-600">
          <div class="flex items-center space-x-2">
            <div :class="['w-3 h-3 rounded-full', isRecording ? 'bg-red-500 animate-pulse' : 'bg-gray-400']"></div>
            <span>ç”¨æˆ·</span>
          </div>
          <div class="flex items-center space-x-2">
            <div :class="['w-3 h-3 rounded-full', isAISpeaking || isAIThinking ? 'bg-nanyu-600 animate-pulse' : 'bg-gray-400']"></div>
            <span>AIåŠ©æ‰‹</span>
          </div>
        </div>
      </div>

      <!-- å³ä¾§ï¼šå¯¹è¯å†å² -->
      <div class="flex-1 h-200 flex flex-col bg-white/80 backdrop-blur-sm border border-gray-200 rounded-2xl shadow-lg overflow-hidden min-w-0 min-h-0">
        <div class="px-6 py-4 border-b border-gray-200 bg-gray-50 flex-shrink-0">
          <h2 class="text-lg font-semibold text-gray-900">å¯¹è¯è®°å½•</h2>
        </div>
        <div
          class="flex-1 overflow-y-scroll p-4 space-y-4 min-h-0 h-0"
          ref="chatContainer"
        >
          <div
            v-for="(message, index) in messages"
            :key="index"
            :class="[
              'flex',
              message.role === 'user' ? 'justify-end' : 'justify-start'
            ]"
          >
            <div
              :class="[
                'max-w-[85%] rounded-lg px-3 py-2 text-sm shadow-sm',
                message.role === 'user'
                  ? 'bg-nanyu-600 text-white'
                  : 'bg-gray-100 text-gray-900'
              ]"
            >
              <div class="font-medium mb-1 text-xs opacity-80">
                {{ message.role === 'user' ? 'æˆ‘' : 'AIåŠ©æ‰‹' }}
              </div>
              <div
                :class="[
                  'whitespace-pre-wrap break-words',
                  message.role === 'user' ? 'text-white' : 'text-gray-700'
                ]"
                v-html="formatMessage(message.content)"
              ></div>
              <div
                :class="[
                  'text-xs mt-1 opacity-70',
                  message.role === 'user' ? 'text-white' : 'text-gray-500'
                ]"
              >
                {{ formatTime(message.timestamp) }}
              </div>
            </div>
          </div>

          <!-- æ­£åœ¨è¾“å…¥æŒ‡ç¤ºå™¨ -->
          <div v-if="isAIThinking" class="flex justify-start">
            <div class="bg-gray-100 rounded-lg px-3 py-2">
              <div class="flex items-center space-x-2">
                <div class="flex space-x-1">
                  <div class="w-1.5 h-1.5 bg-gray-400 rounded-full animate-bounce" style="animation-delay: 0s"></div>
                  <div class="w-1.5 h-1.5 bg-gray-400 rounded-full animate-bounce" style="animation-delay: 0.2s"></div>
                  <div class="w-1.5 h-1.5 bg-gray-400 rounded-full animate-bounce" style="animation-delay: 0.4s"></div>
                </div>
                <span class="text-xs text-gray-500">AIæ­£åœ¨æ€è€ƒ...</span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted, nextTick } from 'vue'
import { marked } from 'marked'
import { AliyunISIASRService } from '@/services/aliyun-isi-asr'
import { streamAIChat } from '@/services/ai-chat'
import { AliyunTTSService, getTTSToken } from '@/services/aliyun-tts'

interface Message {
  role: 'user' | 'assistant'
  content: string
  timestamp: number
}

const messages = ref<Message[]>([])
const isAIThinking = ref(false)
const isAISpeaking = ref(false)
const enableVoiceOutput = ref(true)
const chatContainer = ref<HTMLElement | null>(null)
const audioBars = ref<number[]>(Array(50).fill(2))
const isRecording = ref(false)
const tempTranscript = ref('')
const audioStream = ref<MediaStream | null>(null)

// è¯­éŸ³è¯†åˆ«æœåŠ¡
let asrService: AliyunISIASRService | null = null
let ttsService: AliyunTTSService | null = null
let pendingTextBuffer = ''

// é…ç½® marked
marked.setOptions({
  breaks: true,
  gfm: true,
})

// æ ¼å¼åŒ–æ¶ˆæ¯ï¼ˆMarkdownè½¬HTMLï¼‰
const formatMessage = (content: string) => {
  try {
    return marked(content)
  } catch (error) {
    console.error('Markdownæ¸²æŸ“é”™è¯¯:', error)
    return content.replace(/</g, '&lt;').replace(/>/g, '&gt;')
  }
}

// æ ¼å¼åŒ–æ—¶é—´
const formatTime = (timestamp: number) => {
  const date = new Date(timestamp)
  return date.toLocaleTimeString('zh-CN', { hour: '2-digit', minute: '2-digit' })
}

// æ»šåŠ¨åˆ°åº•éƒ¨
const scrollToBottom = () => {
  nextTick(() => {
    if (chatContainer.value) {
      // ä½¿ç”¨å¹³æ»‘æ»šåŠ¨åˆ°åº•éƒ¨
      chatContainer.value.scrollTo({
        top: chatContainer.value.scrollHeight,
        behavior: 'smooth',
      })
    }
  })
}

// å¤„ç†éŸ³é¢‘æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
const handleAudioData = (data: Uint8Array) => {
  // å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œä¸å¤„ç†éŸ³é¢‘æ•°æ®ï¼ˆä¸æ˜¾ç¤ºæ³¢å½¢ï¼Œä¸æ£€æµ‹å£°éŸ³ï¼‰
  if (isAISpeaking.value) {
    return
  }

  // åªåœ¨å½•éŸ³æ—¶æ›´æ–°å¯è§†åŒ–
  if (!isRecording.value) {
    audioBars.value = Array(50).fill(2)
    return
  }

  const barCount = audioBars.value.length
  const dataLength = data.length

  if (dataLength === 0) {
    audioBars.value = Array(50).fill(2)
    return
  }

  const step = Math.floor(dataLength / barCount)
  const newBars: number[] = []

  for (let i = 0; i < barCount; i++) {
    const index = i * step
    if (index < dataLength) {
      const value = data[index] || 0
      const percentage = Math.max(2, Math.min(100, (value / 255) * 100))
      newBars.push(percentage)
    } else {
      newBars.push(2)
    }
  }

  audioBars.value = newBars
}

// åˆå§‹åŒ–TTSï¼ˆåªåœ¨æ”¶åˆ°AIå“åº”æ—¶è°ƒç”¨ï¼Œä¸å¤„ç†å½•éŸ³é€»è¾‘ï¼‰
const initTTS = async () => {
  if (!enableVoiceOutput.value) {
    return
  }

  // å¦‚æœå·²ç»æœ‰TTSæœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢ä¹‹å‰çš„æ’­æ”¾
  if (ttsService && isAISpeaking.value) {
    console.log('[RealtimeChat] åœæ­¢ä¹‹å‰çš„AIå£°éŸ³æ’­æ”¾ï¼Œå¼€å§‹æ–°çš„æ’­æ”¾')
    stopVoice()
  }

  try {
    console.log('[RealtimeChat] å¼€å§‹è·å–TTS Token')
    const { token, app_key } = await getTTSToken()
    console.log('[RealtimeChat] âœ… TTS Tokenè·å–æˆåŠŸ')

    ttsService = new AliyunTTSService()
    isAISpeaking.value = true
    console.log('[RealtimeChat] åˆ›å»ºTTSæœåŠ¡å®ä¾‹ï¼Œå‡†å¤‡å¯åŠ¨åˆæˆ')

    await ttsService.startSynthesis(
      {
        token,
        appKey: app_key,
        voice: 'longxiaochun',
        format: 'PCM',
        sampleRate: 24000,
        volume: 100,
        speechRate: 0,
        pitchRate: 0,
      },
      () => {
        // onComplete: è¯­éŸ³åˆæˆå®Œæˆï¼ˆæ‰€æœ‰æ–‡æœ¬éƒ½å·²å‘é€åˆ°æœåŠ¡å™¨ï¼‰
        console.log('[RealtimeChat] è¯­éŸ³åˆæˆå®Œæˆï¼ˆæ‰€æœ‰æ–‡æœ¬å·²å‘é€ï¼‰')
        // æ³¨æ„ï¼šè¿™é‡Œä¸è®¾ç½® isAISpeaking = falseï¼Œå› ä¸ºéŸ³é¢‘å¯èƒ½è¿˜åœ¨æ’­æ”¾
      },
      (error: Error) => {
        // onError: è¯­éŸ³åˆæˆå‡ºé”™
        console.error('[RealtimeChat] è¯­éŸ³åˆæˆé”™è¯¯:', error)
        isAISpeaking.value = false
        // æ¸…ç†TTSèµ„æº
        if (ttsService) {
          ttsService.close()
          ttsService = null
        }
        // é”™è¯¯æ—¶ä¸è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨æ“ä½œ
      },
      () => {
        // onPlaybackComplete: éŸ³é¢‘æ’­æ”¾å®Œæˆ
        console.log('[RealtimeChat] âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ')
        isAISpeaking.value = false

        // æ¸…ç†TTSèµ„æº
        if (ttsService) {
          ttsService.close()
          ttsService = null
        }
        pendingTextBuffer = ''

        // AIæ’­æ”¾å®Œæˆåï¼Œè‡ªåŠ¨å¼€å§‹ç›‘å¬ï¼ˆå½•éŸ³ï¼‰
        nextTick(() => {
          if (!isAISpeaking.value && !isAIThinking.value && !isRecording.value) {
            console.log('[RealtimeChat] è‡ªåŠ¨å¼€å§‹å½•éŸ³ç›‘å¬')
            startRecording().catch((error) => {
              console.error('[RealtimeChat] è‡ªåŠ¨å¼€å§‹å½•éŸ³å¤±è´¥:', error)
            })
          } else {
            console.log('[RealtimeChat] çŠ¶æ€ä¸å…è®¸è‡ªåŠ¨å¼€å§‹å½•éŸ³:', {
              isAISpeaking: isAISpeaking.value,
              isAIThinking: isAIThinking.value,
              isRecording: isRecording.value,
            })
          }
        })
      },
    )

    console.log('[RealtimeChat] âœ… TTS startSynthesisè°ƒç”¨å®Œæˆï¼Œç­‰å¾…SynthesisStartedç¡®è®¤')
  } catch (error) {
    console.error('[RealtimeChat] åˆå§‹åŒ–è¯­éŸ³åˆæˆå¤±è´¥:', error)
    enableVoiceOutput.value = false
    isAISpeaking.value = false
    ttsService = null
  }
}

// å‘é€æ–‡æœ¬è¿›è¡Œè¯­éŸ³åˆæˆ
const synthesizeText = (text: string) => {
  if (!ttsService || !enableVoiceOutput.value) {
    return
  }

  try {
    pendingTextBuffer += text

    // å¦‚æœç¼“å†²åŒºæœ‰å†…å®¹ï¼Œç«‹å³å‘é€ï¼ˆä¸ç­‰å¾…å¥å­ç»“æŸï¼‰ï¼Œé¿å…è¶…æ—¶
    if (pendingTextBuffer.trim().length > 0) {
      // æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¥å­
      if (/[ã€‚ï¼ï¼Ÿ\n]/.test(text)) {
        const sentences = pendingTextBuffer.split(/([ã€‚ï¼ï¼Ÿ\n])/)
        for (let i = 0; i < sentences.length - 1; i += 2) {
          const sentence = sentences[i] + sentences[i + 1]
          if (sentence.trim()) {
            ttsService.sendText(sentence.trim())
          }
        }
        pendingTextBuffer = sentences[sentences.length - 1] || ''
      } else if (pendingTextBuffer.length >= 5) {
        // è¿›ä¸€æ­¥é™ä½é˜ˆå€¼ï¼Œæ›´é¢‘ç¹åœ°å‘é€ï¼Œé¿å…è¶…æ—¶ï¼ˆä»10é™åˆ°5ï¼‰
        console.log('[RealtimeChat] å‘é€æ–‡æœ¬ç‰‡æ®µåˆ°TTSï¼ˆè¾¾åˆ°é˜ˆå€¼ï¼‰:', pendingTextBuffer.substring(0, 50))
        ttsService.sendText(pendingTextBuffer)
        pendingTextBuffer = ''
      } else {
        // å³ä½¿æ²¡æœ‰è¾¾åˆ°é˜ˆå€¼ï¼Œå¦‚æœæœ‰å†…å®¹ä¹Ÿç«‹å³å‘é€ï¼ˆé¿å…è¶…æ—¶ï¼‰
        // ä½†è‡³å°‘è¦æœ‰1ä¸ªå­—ç¬¦
        if (pendingTextBuffer.trim().length >= 1 && text.trim().length > 0) {
          console.log('[RealtimeChat] å‘é€æ–‡æœ¬ç‰‡æ®µåˆ°TTSï¼ˆä¿æŒè¿æ¥ï¼‰:', pendingTextBuffer.substring(0, 50))
          ttsService.sendText(pendingTextBuffer.trim())
          pendingTextBuffer = ''
        }
      }
    }
  } catch (error) {
    console.error('[RealtimeChat] å‘é€æ–‡æœ¬åˆ°TTSå¤±è´¥:', error)
    // å¦‚æœæ˜¯å› ä¸ºåˆæˆæœªå¼€å§‹ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–
    if (error instanceof Error && error.message.includes('Synthesis has not started')) {
      console.log('[RealtimeChat] TTSåˆæˆæœªå¼€å§‹ï¼Œå°è¯•é‡æ–°åˆå§‹åŒ–')
      // ä¸åœ¨è¿™é‡Œé‡æ–°åˆå§‹åŒ–ï¼Œé¿å…å¾ªç¯è°ƒç”¨
    }
  }
}

// åœæ­¢è¯­éŸ³æ’­æ”¾
const stopVoice = () => {
  if (ttsService) {
    ttsService.stopPlayback()
    ttsService.stopSynthesis()
    ttsService.close()
    ttsService = null
  }
  pendingTextBuffer = ''
  isAISpeaking.value = false
}

// å‘é€AIæ¶ˆæ¯
const sendAIMessage = async () => {
  isAIThinking.value = true

  // æ ‡è®°æ˜¯å¦å·²ç»åˆå§‹åŒ–TTSï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œåœ¨æ”¶åˆ°ç¬¬ä¸€ä¸ªchunkæ—¶æ‰åˆå§‹åŒ–ï¼‰
  let ttsInitialized = false

  // æ„å»ºèŠå¤©å†å²ï¼ˆåªä¿ç•™æœ€è¿‘çš„å¯¹è¯ï¼Œè½¬æ¢ä¸ºOpenAIæ ¼å¼ï¼‰
  const recentMessages = messages.value.slice(-10).map(msg => ({
    role: msg.role === 'user' ? 'user' as const : 'assistant' as const,
    content: msg.content,
  }))

  try {
    await streamAIChat(
      undefined, // ä¸éœ€è¦ä¼šè®®ID
      recentMessages, // ä¼ é€’æ¶ˆæ¯æ•°ç»„
      async (chunk: string) => {
        // å®æ—¶è¿½åŠ æ–‡æœ¬
        const lastMessage = messages.value[messages.value.length - 1]
        if (lastMessage && lastMessage.role === 'assistant') {
          lastMessage.content += chunk
        } else {
          messages.value.push({
            role: 'assistant',
            content: chunk,
            timestamp: Date.now(),
          })
        }
        scrollToBottom()

        // å¦‚æœå¯ç”¨è¯­éŸ³ï¼Œå»¶è¿Ÿåˆå§‹åŒ–TTSï¼ˆåœ¨æ”¶åˆ°ç¬¬ä¸€ä¸ªchunkæ—¶æ‰åˆå§‹åŒ–ï¼‰
        if (enableVoiceOutput.value) {
          if (!ttsInitialized && !ttsService) {
            console.log('[RealtimeChat] æ”¶åˆ°ç¬¬ä¸€ä¸ªAIå“åº”chunkï¼Œå¼€å§‹åˆå§‹åŒ–TTSï¼Œchunkå†…å®¹:', chunk.substring(0, 50))
            ttsInitialized = true
            try {
              console.log('[RealtimeChat] å‡†å¤‡åˆå§‹åŒ–TTSï¼Œchunkå†…å®¹:', chunk.substring(0, 50))
              await initTTS()
              console.log('[RealtimeChat] TTSåˆå§‹åŒ–å®Œæˆï¼ŒttsServiceçŠ¶æ€:', ttsService ? 'å­˜åœ¨' : 'ä¸å­˜åœ¨')

              // TTSåˆå§‹åŒ–æˆåŠŸåï¼Œç«‹å³å‘é€ç¬¬ä¸€ä¸ªchunkï¼Œé¿å…è¿æ¥ç©ºé—²è¶…æ—¶
              if (ttsService && chunk.trim()) {
                console.log('[RealtimeChat] TTSåˆå§‹åŒ–æˆåŠŸï¼Œç«‹å³å‘é€ç¬¬ä¸€ä¸ªchunk:', chunk.substring(0, 50))
                // ç›´æ¥å‘é€ï¼Œä¸ä½¿ç”¨ç¼“å†²åŒºï¼Œç¡®ä¿ç«‹å³å‘é€
                try {
                  // TypeScriptç±»å‹æ–­è¨€ï¼Œç¡®ä¿ç±»å‹æ­£ç¡®
                  (ttsService as AliyunTTSService).sendText(chunk.trim())
                  console.log('[RealtimeChat] âœ… ç¬¬ä¸€ä¸ªchunkå·²å‘é€åˆ°TTS')
                } catch (sendError) {
                  console.error('[RealtimeChat] å‘é€ç¬¬ä¸€ä¸ªchunkå¤±è´¥:', sendError)
                }
              } else {
                console.warn('[RealtimeChat] TTSåˆå§‹åŒ–åæ— æ³•å‘é€chunk:', {
                  ttsService: !!ttsService,
                  chunk: chunk.substring(0, 50),
                  chunkTrimmed: chunk.trim(),
                })
              }
            } catch (error) {
              console.error('[RealtimeChat] TTSåˆå§‹åŒ–å¤±è´¥:', error)
              // å³ä½¿TTSåˆå§‹åŒ–å¤±è´¥ï¼Œä¹Ÿç»§ç»­å¤„ç†æ–‡æœ¬
            }
          } else {
            // å¦‚æœTTSå·²åˆå§‹åŒ–ï¼Œå®æ—¶åˆæˆè¯­éŸ³
            if (ttsService) {
              synthesizeText(chunk)
            }
          }
        }
      },
      () => {
        // æµç»“æŸï¼šAIå›å¤å®Œæ¯•
        isAIThinking.value = false
        console.log('[RealtimeChat] âœ… AIå›å¤å®Œæ¯•')

        // å¦‚æœå¯ç”¨è¯­éŸ³ï¼Œå‘é€å‰©ä½™çš„æ–‡æœ¬å¹¶å…³é—­TTSè¿æ¥
        if (enableVoiceOutput.value && ttsService) {
          // å‘é€å‰©ä½™çš„æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
          if (pendingTextBuffer.trim()) {
            console.log('[RealtimeChat] å‘é€å‰©ä½™çš„æ–‡æœ¬åˆ°TTS:', pendingTextBuffer.trim().substring(0, 50))
            ttsService.sendText(pendingTextBuffer.trim())
            pendingTextBuffer = ''
          }

          // å‘é€StopSynthesisæŒ‡ä»¤ï¼Œå…³é—­TTSè¿æ¥ï¼ˆä½†éŸ³é¢‘ä¼šç»§ç»­æ’­æ”¾ç›´åˆ°å®Œæˆï¼‰
          console.log('[RealtimeChat] AIå›å¤å®Œæ¯•ï¼Œå‘é€StopSynthesiså¹¶å…³é—­TTSè¿æ¥')
          ttsService.stopSynthesis()
          // æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œè°ƒç”¨ ttsService.close()ï¼Œè®©éŸ³é¢‘ç»§ç»­æ’­æ”¾
          // close() ä¼šåœ¨ onPlaybackComplete å›è°ƒä¸­è°ƒç”¨
        }
      },
      (error: Error) => {
        // é”™è¯¯å¤„ç†
        console.error('[RealtimeChat] AIå¯¹è¯å¤±è´¥:', {
          error,
          message: error.message,
          name: error.name,
          stack: error.stack,
        })

        // æ„å»ºè¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯
        let errorMessage = `æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼š${error.message}`
        if (error.name && error.name !== 'Error') {
          errorMessage += `\n\né”™è¯¯ç±»å‹ï¼š${error.name}`
        }

        // æ·»åŠ å¸¸è§é”™è¯¯çš„è§£å†³å»ºè®®
        if (error.message.includes('HTTP 401') || error.message.includes('æœªç™»å½•')) {
          errorMessage += '\n\næç¤ºï¼šè¯·æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•ã€‚'
        } else if (error.message.includes('HTTP 500')) {
          errorMessage += '\n\næç¤ºï¼šæœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚'
        } else if (error.message.includes('ç½‘ç»œ') || error.message.includes('fetch')) {
          errorMessage += '\n\næç¤ºï¼šç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚'
        }

        messages.value.push({
          role: 'assistant',
          content: errorMessage,
          timestamp: Date.now(),
        })
        scrollToBottom()
        isAIThinking.value = false
        stopVoice()
      },
    )
  } catch (error) {
    console.error('[RealtimeChat] è°ƒç”¨AIå¯¹è¯æœåŠ¡å¤±è´¥:', {
      error,
      message: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯',
      stack: error instanceof Error ? error.stack : undefined,
    })

    let errorMessage = `æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
    if (error instanceof Error && error.name && error.name !== 'Error') {
      errorMessage += `\n\né”™è¯¯ç±»å‹ï¼š${error.name}`
    }

    messages.value.push({
      role: 'assistant',
      content: errorMessage,
      timestamp: Date.now(),
    })
    scrollToBottom()
    isAIThinking.value = false
    stopVoice()
  }
}

// è·å–éº¦å…‹é£æƒé™
const getMicrophonePermission = async (): Promise<MediaStream> => {
  // æ£€æŸ¥ç°æœ‰æµæ˜¯å¦æœ‰æ•ˆï¼ˆæ‰€æœ‰è½¨é“éƒ½å¤„äºæ´»åŠ¨çŠ¶æ€ï¼‰
  if (audioStream.value) {
    const tracks = audioStream.value.getTracks()
    const allActive = tracks.length > 0 && tracks.every(track => track.readyState === 'live')

    if (allActive) {
      console.log('[RealtimeChat] ä½¿ç”¨ç°æœ‰çš„éŸ³é¢‘æµ')
      return audioStream.value
    } else {
      console.log('[RealtimeChat] ç°æœ‰éŸ³é¢‘æµå·²åœæ­¢ï¼Œéœ€è¦é‡æ–°è·å–')
      // æ¸…ç†æ— æ•ˆçš„æµ
      audioStream.value.getTracks().forEach(track => track.stop())
      audioStream.value = null
    }
  }

  try {
    console.log('[RealtimeChat] è·å–æ–°çš„éº¦å…‹é£æƒé™')
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
      },
    })
    audioStream.value = stream
    console.log('[RealtimeChat] âœ… æˆåŠŸè·å–éº¦å…‹é£æƒé™')
    return stream
  } catch (error) {
    console.error('[RealtimeChat] è·å–éº¦å…‹é£æƒé™å¤±è´¥:', error)
    audioStream.value = null
    throw new Error('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®')
  }
}

// åˆ‡æ¢å½•éŸ³
const toggleRecording = async () => {
  // å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œç¦æ­¢å½•éŸ³
  if (isAISpeaking.value) {
    console.log('[RealtimeChat] AIæ­£åœ¨è¯´è¯ï¼Œç¦æ­¢å½•éŸ³ï¼Œè¯·ç­‰å¾…AIè¯´å®Œ')
    return
  }

  if (isRecording.value) {
    stopRecording()
  } else {
    await startRecording()
  }
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  // å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œç¦æ­¢å½•éŸ³
  if (isAISpeaking.value) {
    console.log('[RealtimeChat] AIæ­£åœ¨è¯´è¯ï¼Œç¦æ­¢å¼€å§‹å½•éŸ³')
    return
  }

  // å¦‚æœå·²ç»åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢
  if (isRecording.value && asrService) {
    console.log('[RealtimeChat] å·²ç»åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢ä¹‹å‰çš„å½•éŸ³')
    stopRecording()
    // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿èµ„æºæ¸…ç†å®Œæˆ
    await new Promise(resolve => setTimeout(resolve, 100))
  }

  try {
    console.log('[RealtimeChat] å¼€å§‹å½•éŸ³æµç¨‹')

    // è·å–éº¦å…‹é£æƒé™ï¼ˆä¼šæ£€æŸ¥æµæ˜¯å¦æœ‰æ•ˆï¼Œæ— æ•ˆåˆ™é‡æ–°è·å–ï¼‰
    const stream = await getMicrophonePermission()

    // åˆ›å»ºæ–°çš„ISI ASRæœåŠ¡å®ä¾‹ï¼ˆç¡®ä¿æ˜¯å…¨æ–°çš„å®ä¾‹ï¼‰
    console.log('[RealtimeChat] åˆ›å»ºæ–°çš„ASRæœåŠ¡å®ä¾‹')
    asrService = new AliyunISIASRService()

    // 4. è®¾ç½®å›è°ƒ
    asrService.onResult((result) => {
      console.log('[RealtimeChat] è¯†åˆ«ç»“æœ:', result)

      // å¦‚æœAIæ­£åœ¨è¯´è¯ï¼Œå¿½ç•¥è¯†åˆ«ç»“æœï¼ˆä¸å¤„ç†ï¼Œä¸æ˜¾ç¤ºï¼‰
      if (isAISpeaking.value) {
        console.log('[RealtimeChat] AIæ­£åœ¨è¯´è¯ï¼Œå¿½ç•¥è¯­éŸ³è¯†åˆ«ç»“æœ')
        return
      }

      if (result.isFinal) {
        // æœ€ç»ˆç»“æœ
        if (result.text.trim()) {
          // æ¸…ç©ºä¸´æ—¶æ˜¾ç¤º
          tempTranscript.value = ''
          // å‘é€æ¶ˆæ¯
          handleSendMessageFromVoice(result.text.trim())
        }
      } else {
        // ä¸­é—´ç»“æœï¼Œå®æ—¶æ˜¾ç¤º
        tempTranscript.value = result.text
      }
    })

    asrService.onError((error) => {
      console.error('[RealtimeChat] è¯­éŸ³è¯†åˆ«é”™è¯¯:', error)
      isRecording.value = false
      alert(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}`)
    })

    asrService.onAudioData(handleAudioData)

    // 5. å¼€å§‹è¯†åˆ«ï¼ˆISIæœåŠ¡ä¼šè‡ªåŠ¨è¿æ¥WebSocketå¹¶è·å–Tokenï¼‰
    await asrService.startRecognition(stream)

    isRecording.value = true
    console.log('[RealtimeChat] è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨')
  } catch (error) {
    console.error('[RealtimeChat] å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
    isRecording.value = false
    alert(`å¯åŠ¨å½•éŸ³å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`)
  }
}

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  console.log('[RealtimeChat] åœæ­¢å½•éŸ³')

  if (asrService) {
    asrService.stopRecognition()
    asrService = null
  }

  // æ¸…ç†éŸ³é¢‘æµï¼ˆASRæœåŠ¡å·²ç»åœæ­¢äº†æµï¼Œä½†æˆ‘ä»¬éœ€è¦æ¸…ç†å¼•ç”¨ï¼‰
  // æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œåœæ­¢æµï¼Œå› ä¸ºASRæœåŠ¡å·²ç»å¤„ç†äº†
  // ä½†éœ€è¦æ¸…ç†å¼•ç”¨ï¼Œä»¥ä¾¿ä¸‹æ¬¡é‡æ–°è·å–
  if (audioStream.value) {
    const tracks = audioStream.value.getTracks()
    const allEnded = tracks.every(track => track.readyState === 'ended')
    if (allEnded) {
      console.log('[RealtimeChat] éŸ³é¢‘æµå·²ç»“æŸï¼Œæ¸…ç†å¼•ç”¨')
      audioStream.value = null
    }
  }

  isRecording.value = false
  tempTranscript.value = ''
  audioBars.value = Array(50).fill(2)
  console.log('[RealtimeChat] âœ… å½•éŸ³å·²åœæ­¢')
}

// ä»è¯­éŸ³è¯†åˆ«ç»“æœå‘é€æ¶ˆæ¯
const handleSendMessageFromVoice = async (text: string) => {
  if (!text.trim()) {
    return
  }

  // å¦‚æœAIæ­£åœ¨æ€è€ƒï¼Œç­‰å¾…å®Œæˆ
  if (isAIThinking.value) {
    console.log('[RealtimeChat] AIæ­£åœ¨æ€è€ƒï¼Œç­‰å¾…å®Œæˆåå†å‘é€æ¶ˆæ¯')
    // å¯ä»¥é€‰æ‹©ç­‰å¾…æˆ–è€…ç›´æ¥æ·»åŠ æ¶ˆæ¯
    // è¿™é‡Œé€‰æ‹©ç›´æ¥æ·»åŠ æ¶ˆæ¯ï¼Œä¸ç­‰å¾…AIå®Œæˆ
  }

  // åœæ­¢å½•éŸ³ï¼ˆåœ¨å‘é€AIæ¶ˆæ¯ä¹‹å‰ï¼‰
  if (isRecording.value) {
    console.log('[RealtimeChat] ç”¨æˆ·æ¶ˆæ¯å·²è¯†åˆ«ï¼Œåœæ­¢å½•éŸ³ï¼Œå‡†å¤‡å‘é€ç»™AI')
    stopRecording()
  }

  // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
  const userMessage = {
    role: 'user' as const,
    content: text.trim(),
    timestamp: Date.now(),
  }

  messages.value.push(userMessage)
  console.log('[RealtimeChat] å·²æ·»åŠ ç”¨æˆ·æ¶ˆæ¯:', userMessage)

  scrollToBottom()

  // å‘é€AIè¯·æ±‚
  await sendAIMessage()
}

// æ¸…ç©ºå¯¹è¯
const clearChat = () => {
  if (confirm('ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰å¯¹è¯è®°å½•å—ï¼Ÿ')) {
    messages.value = []
    stopVoice()
  }
}

onMounted(() => {
  // æ·»åŠ æ¬¢è¿æ¶ˆæ¯å’Œæ¨¡æ‹Ÿå¯¹è¯æ ·ä¾‹
  const now = Date.now()

  messages.value.push({
    role: 'assistant',
    content: 'ä½ å¥½ï¼æˆ‘æ˜¯å¤‡è¯¾AIåŠ©æ‰‹ï¼Œå¯ä»¥ä¸ä½ è¿›è¡Œå®æ—¶è¯­éŸ³å¯¹è¯ï¼Œå¸®åŠ©ä½ è¿›è¡Œæ•™å­¦å‡†å¤‡å’Œè®¨è®ºã€‚ç‚¹å‡»ä¸­é—´çš„æŒ‰é’®å¼€å§‹è¯´è¯ï¼Œæˆ‘ä¼šå®æ—¶è¯†åˆ«ä½ çš„è¯­éŸ³å¹¶ä¸ºä½ æä¾›ä¸“ä¸šçš„æ•™å­¦å»ºè®®å’Œå¤‡è¯¾æ”¯æŒã€‚',
    timestamp: now - 300000,
  })
  // ç¡®ä¿åˆå§‹æ—¶æ»šåŠ¨åˆ°åº•éƒ¨
  scrollToBottom()
})

onUnmounted(() => {
  stopVoice()
  stopRecording()
  // æ¸…ç†éŸ³é¢‘æµ
  if (audioStream.value) {
    audioStream.value.getTracks().forEach(track => track.stop())
    audioStream.value = null
  }
})
</script>

<style scoped>
/* Markdownå†…å®¹æ ·å¼ */
:deep(.markdown-body) {
  line-height: 1.6;
}

:deep(.markdown-body h1),
:deep(.markdown-body h2),
:deep(.markdown-body h3) {
  font-weight: 600;
  margin-top: 0.5em;
  margin-bottom: 0.25em;
  font-size: 1em;
}

:deep(.markdown-body p) {
  margin-bottom: 0.5em;
}

:deep(.markdown-body code) {
  background-color: rgba(0, 0, 0, 0.1);
  padding: 0.2em 0.4em;
  border-radius: 0.25rem;
  font-size: 0.85em;
}

:deep(.markdown-body pre) {
  background-color: rgba(0, 0, 0, 0.05);
  padding: 0.5em;
  border-radius: 0.25rem;
  overflow-x: auto;
  margin: 0.5em 0;
}

:deep(.markdown-body pre code) {
  background-color: transparent;
  padding: 0;
}

/* èŠå¤©è®°å½•æ»šåŠ¨æ¡æ ·å¼ - ç¡®ä¿æ»šåŠ¨æ¡æ˜æ˜¾å¯è§ */
.chat-container {
  scrollbar-width: thin;
  scrollbar-color: rgba(107, 114, 128, 0.9) rgba(229, 231, 235, 0.5);
  /* ç¡®ä¿å¯ä»¥æ»šåŠ¨ */
  position: relative;
}

.chat-container::-webkit-scrollbar {
  width: 10px;
  /* ç¡®ä¿æ»šåŠ¨æ¡å§‹ç»ˆæ˜¾ç¤º */
  -webkit-appearance: none;
}

.chat-container::-webkit-scrollbar-track {
  background: rgba(229, 231, 235, 0.5);
  border-radius: 5px;
  margin: 4px 0;
}

.chat-container::-webkit-scrollbar-thumb {
  background-color: rgba(107, 114, 128, 0.9);
  border-radius: 5px;
  border: 2px solid rgba(229, 231, 235, 0.5);
  min-height: 30px;
}

.chat-container::-webkit-scrollbar-thumb:hover {
  background-color: rgba(75, 85, 99, 1);
}

.chat-container::-webkit-scrollbar-thumb:active {
  background-color: rgba(55, 65, 81, 1);
}
</style>
